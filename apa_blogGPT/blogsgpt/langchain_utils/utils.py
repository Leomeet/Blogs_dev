import openai
import os

from langchain.chains.qa_with_sources import load_qa_with_sources_chain
from langchain.schema import Document
from langchain.callbacks import get_openai_callback
from langchain.memory import ConversationSummaryMemory
from langchain.llms import OpenAI

from backend.prompts import FINAL_PROMPT
from db.vecstore import Vecstore


class LangchainUtils:
    """
    Langchain and embeddings utility functions
    """

    def conversational_summary(self):
        """return conversational memory object"""
        return ConversationSummaryMemory(
            llm=OpenAI(
                temperature=0,
                openai_api_key=os.environ.get("OPENAI_API_KEY"),
            ),
        )

    def doc_search_faiss(self, index, query):
        """searching for similar embeddings in provided index
        : index - pkl or faiss embedding file data
        : query - query embeddings to compare to

        Returns:
            : document sources
        """
        response = openai.Embedding.create(model="text-embedding-ada-002", input=query)
        embedding = response["data"][0]["embedding"]
        docsearch = index.similarity_search_by_vector(embedding, k=2)
        return docsearch

    def doc_search_vecstore(self, index: str, query: str):
        """vector database search with index / collection name and given query

        Args:
            index (str): name of the collection
            query (str): asked question

        Returns:
            obj: collection of relevant documents
        """
        vecstore = Vecstore()
        vecstore.load_collection(index)
        docsearch = vecstore.search_with_index(index, query)
        return self.format_docsearch(docsearch)

    def format_docsearch(self, docsearch):
        """formatting the milvus result object to a list of document object for langchain

        docsearch: milvus result object
        """
        result_object = []
        for result in docsearch[0]:
            # here content is the name of my output field that holds text information
            text_info = result.entity.get("content")
            doc = Document(page_content=text_info, metadata={"source": result.score})
            # pair = (doc, result.score)
            result_object.append(doc)
        return result_object

    def get_answer(self, docsearch, query, chat_history, is_user_uploaded_data):
        """generates ans with api call to OpenAI

        Args:
            docsearch: searched documents sources
            query: question asked by user
            chat_history : summary of previous messages
            is_user_uploaded_data (bool): to search with prompt template

        Returns:
            response from api call
        """
        llm = OpenAI(temperature=0.7, openai_api_key=os.environ.get("OPENAI_API_KEY"))

        if is_user_uploaded_data:
            search_chain = load_qa_with_sources_chain(
                llm=llm,
                chain_type="stuff",
                prompt=FINAL_PROMPT,
            )
        else:
            search_chain = load_qa_with_sources_chain(llm=llm, chain_type="stuff")

        answer = search_chain(
            {
                "input_documents": docsearch,
                "question": query,
                "history": chat_history,
            },
            return_only_outputs=True,
        )

        return answer

    def get_sources(self, answer, docs, is_user_uploaded_data):
        """gets sources information from given answer

        Args:
            answer (_type_): answer generated by ai
            docs (_type_): document to search into
            is_user_uploaded_data (bool): custom data

        Returns:
            : returns sources of generated ans
        """
        source_keys = list(answer["output_text"].split("SOURCES: ")[-1].split(","))

        if not is_user_uploaded_data:
            return source_keys

        source_docs = []
        for doc in docs:
            if doc.metadata["source"] in source_keys:
                source_docs.append(doc)

        return source_docs

    def wrap_text_in_html(self, text) -> str:
        """Wraps each text block separated by newlines in <p> tags"""
        if isinstance(text, list):
            text = "\n<hr/>\n".join(text)

        return "".join([f"<p>{line}</p>" for line in text.split("\n")])
